{"cells":[{"cell_type":"markdown","metadata":{"id":"DymRJbxDBCnf"},"source":["# **INFO5731 In-class Exercise 2**\n","\n","The purpose of this exercise is to understand users' information needs, and then collect data from different sources for analysis by implementing web scraping using Python.\n","\n","**Expectations**:\n","*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n","*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n","*   Write complete answers and run all the cells before submission.\n","*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n","*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n","\n","**Total points**: 40\n","\n","**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n","\n","**Late submissions will have a penalty of 10% of the marks for each day of late submission. , and no requests will be answered. Manage your time accordingly.**\n"]},{"cell_type":"markdown","source":["## Question 1 (10 Points)\n","Describe an interesting research question (or practical question or something innovative) you have in mind, what kind of data should be collected to answer the question(s)? Specify the amount of data needed for analysis. Provide detailed steps for collecting and saving the data."],"metadata":{"id":"FBKvD6O_TY6e"}},{"cell_type":"markdown","source":["#\"Could wearable biometric data forecast the development of decision fatigue among people taking challenging decisions throughout the day?\"\n","\n","Synopsis:\n","People who make a lot of judgments during the day may become weary of them, which could affect the caliber and speed of their decisions. Through the examination of physiological information (heart rate, skin temperature, and stress levels), we can ascertain whether there exist quantifiable markers that forecast the onset of decision fatigue. This may result in customized solutions that support people in keeping their minds clear when making decisions.\n","\n","\n","##Data Collection Plan:\n","\n","###Biometric Data:\n","1)Modulation of heart rate\n","\n","2)temperature of the skin\n","\n","3)sleep statistics\n","\n","4) Exercise\n","\n","###Mental Performance:\n"," 1)Decision-making time\n","\n"," 2)Decision-making quality and accuracy\n","\n","###Decision Perspective:\n","1)Total number of decisions made in a day\n","\n","2)Decision difficulty\n","\n","###Emotional Information:\n","1)Mental tiredness\n","\n","2)Self-reported decision-making\n","\n","##Amount of Data Needed:\n","50â€“100 people, covering various lifestyles and professions.\n","\n","To examine patterns and variability in daily decision fatigue over time, data should be collected for a minimum of three to four months.\n","\n","Wearable technology is used to continuously collect biometric data.\n","\n","Decision-making and thinking-making information gathered following each session of decision-making\n","\n","##Steps to collect and save the data:\n","\n","###Enrollment of Participants:\n","Find participants who make judgments on a daily basis, such as students, entrepreneurs, or those in high-risk positions. Teach participants how to use a basic smartphone app or survey platform to gather subjective data.\n","\n","###Biometric Data Collection:\n","Now we need to collect biometric data from variables such as Modulation of heart rate, skin temperature, sleep stats and excercise routine to assess ceretian factors like stress, mental stability,fluctuations that may indicate  fatigue, physical activity and sleep cycle.\n","\n","###Decision-making skills:\n","Create a decision-logging application that allows users to score mental effort, confidence, and weariness as well as record and categorize daily decisions. Automatic reminders should be set up to remind users to enter the data on a regular basis.Provide controlled decision-making exercises with a range of difficulty levels for puzzles, strategic games, and logic challenges. To replicate decision fatigue patterns, repeat activities throughout the day, vary task difficulty, and measure time and accuracy.\n","\n","###Data Management and Storage:\n","Utilize Participant ID, Date & Time, and biometric information to organize data (sleep, activity, GSR, HRV, and skin temperature). Factors such as work kind, difficulty, duration, accuracy, effort, and confidence should be considered while making decisions. Keep subjective measurements (such as energy, weariness, and mood) encrypted in a safe cloud database.\n","\n","###Analysis:\n","Investigate relationships between biometric markers and decision fatigue using data analytic technologies. Use machine learning models to analyze heart rate variability, skin temperature, GSR, sleep, and activity to forecast the onset, accuracy, and decision time of weariness.\n","\n","##Conclusion:\n","This study could contribute to our understanding of decision fatigue and inspire novel approaches, including wearable apps that recommend breaks or modifications to enhance cognitive function during times when decision-making demands are high.\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"J8ro0Ghcz806"}},{"cell_type":"markdown","source":["## Question 2 (10 Points)\n","Write Python code to collect a dataset of 1000 samples related to the question discussed in Question 1."],"metadata":{"id":"E9RqrlwdTfvl"}},{"cell_type":"code","source":["import random\n","import pandas as pd\n","\n","# biometric data and decision fatigue simulation\n","def data_simulation(samples):\n","    dt = []\n","    for _ in range(samples):\n","        decisions = random.randint(5, 15)\n","        difficulty = random.choice([1, 2, 3, 4, 5])\n","        fatigue = min(15, random.uniform(1, 5) + decisions * 0.2 * difficulty)\n","        hrv = max(40, 80 - fatigue * 3)\n","        skin_temperature = 98 + fatigue * 0.2\n","        stress = random.uniform(1, 20) if fatigue > 5 else random.uniform(5, 10)\n","\n","        dt.append([decisions, difficulty, fatigue, hrv, skin_temperature, stress])\n","\n","    return dt\n","\n","# dataset creation\n","samples = 1000\n","columns = ['decisions', 'difficulty', 'fatigue', 'hrv', 'skin_temperature', 'stress']\n","dataset = data_simulation(samples)\n","\n","# Saving data to csv\n","df = pd.DataFrame(dataset, columns=columns)\n","df.to_csv('biometric data .csv', index=False)\n","\n","print(\"Dataset saved as 'biometric data.csv'\")\n"],"metadata":{"id":"4XvRknixTh1g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726411052875,"user_tz":300,"elapsed":179,"user":{"displayName":"VIJAY REDDY","userId":"13446931600515560470"}},"outputId":"f4b18db4-f94e-4cd0-8186-e2fd2ae559a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset saved as 'biometric data.csv'\n"]}]},{"cell_type":"markdown","metadata":{"id":"03jb4GZsBkBS"},"source":["## Question 3 (10 Points)\n","Write Python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"XYZ\". The articles should be published in the last 10 years (2014-2024).\n","\n","The following information from the article needs to be collected:\n","\n","(1) Title of the article\n","\n","(2) Venue/journal/conference being published\n","\n","(3) Year\n","\n","(4) Authors\n","\n","(5) Abstract"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"YaGLbSHHB8Ej","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726435119660,"user_tz":300,"elapsed":1194,"user":{"displayName":"VIJAY REDDY","userId":"13446931600515560470"}},"outputId":"556f403f-3aad-40d2-f985-84bb6768124e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unable to retrieve data\n","Data collected and saved as 'articles_data.csv'.\n"]}],"source":["import requests\n","import pandas as pd\n","from datetime import datetime\n","\n","\n","#Article retrieval function from the Semantic Scholar API\n","def articles(keyphrases, start_year, end_year, article_count):\n","    url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n","    params = {\n","        \"object\": keyphrases,\n","        \"limit\": article_count,\n","        \"year\": f\"{start_year}-{end_year}\",\n","        \"cols\": \"title,venue,year,authors,abstract\"\n","    }\n","\n","    decision = requests.get(url, params=params)\n","    if decision.status_code != 100:\n","        print(\"Unable to retrieve data\")\n","        return []\n","\n","    data = decision.json()\n","    articles = data.get(\"data\", [])\n","\n","    results = []\n","    for article in articles:\n","        title = article.get(\"title\")\n","        venue = article.get(\"venue\")\n","        year = article.get(\"year\")\n","        authors = \", \".join([author.get(\"name\") for author in article.get(\"authors\", [])])\n","        abstract = article.get(\"abstract\")\n","\n","        results.append({\n","            \"Title\": title,\n","            \"Venue/Journal/Conference\": venue,\n","            \"Year\": year,\n","            \"Authors\": authors,\n","            \"Abstract\": abstract\n","        })\n","\n","    return results\n","\n","# Specifications\n","keyphrases = \"XYZ\"\n","start_year = 2014\n","end_year = 2024\n","article_count = 1000\n","\n","# data fetching\n","articles = articles(keyphrases, start_year, end_year, article_count)\n","\n","#Dataframe\n","df = pd.DataFrame(articles)\n","\n","# Saving data to csv\n","df.to_csv('articles_data.csv', index=False)\n","\n","print(f\"Data collected and saved as 'articles_data.csv'.\")\n"]},{"cell_type":"markdown","metadata":{"id":"jJDe71iLB616"},"source":["## Question 4A (10 Points)\n","Develop Python code to collect data from social media platforms like Reddit, Instagram, Twitter (formerly known as X), Facebook, or any other. Use hashtags, keywords, usernames, or user IDs to gather the data.\n","\n","\n","\n","Ensure that the collected data has more than four columns.\n"]},{"cell_type":"code","source":[],"metadata":{"id":"gzTGIyQkW0Ph"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"55W9AMdXCSpV"},"source":["## Question 4B (10 Points)\n","If you encounter challenges with Question-4 web scraping using Python, employ any online tools such as ParseHub or Octoparse for data extraction. Introduce the selected tool, outline the steps for web scraping, and showcase the final output in formats like CSV or Excel.\n","\n","\n","\n","Upload a document (Word or PDF File) in any shared storage (preferably UNT OneDrive) and add the publicly accessible link in the below code cell.\n","\n","Please only choose one option for question 4. If you do both options, we will grade only the first one"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"I57NXsauCec2","executionInfo":{"status":"ok","timestamp":1726434999567,"user_tz":300,"elapsed":197,"user":{"displayName":"VIJAY REDDY","userId":"13446931600515560470"}}},"outputs":[],"source":["# write your answer here\n","https://myunt-my.sharepoint.com/:f:/g/personal/vijayaramareddymallidi_my_unt_edu/EnFhduZ1d5RFqjdF5tacthABPYeqykk0xHJWWBpxGNzMiw?e=EY3flT"]},{"cell_type":"markdown","source":["# Mandatory Question"],"metadata":{"id":"sZOhks1dXWEe"}},{"cell_type":"markdown","source":["**Important: Reflective Feedback on Web Scraping and Data Collection**\n","\n","\n","\n","Please share your thoughts and feedback on the web scraping and data collection exercises you have completed in this assignment. Consider the following points in your response:\n","\n","\n","\n","Learning Experience: Describe your overall learning experience in working on web scraping tasks. What were the key concepts or techniques you found most beneficial in understanding the process of extracting data from various online sources?\n","\n","\n","\n","Challenges Encountered: Were there specific difficulties in collecting data from certain websites, and how did you overcome them? If you opted for the non-coding option, share your experience with the chosen tool.\n","\n","\n","\n","Relevance to Your Field of Study: How might the ability to gather and analyze data from online sources enhance your work or research?\n","\n","**(no grading of your submission if this question is left unanswered)**"],"metadata":{"id":"eqmHVEwaWhbV"}},{"cell_type":"code","source":["'''\n","\n","Working on web scraping tasks was a valuable experience, teaching key concepts like HTML structure, pagination, and dynamic content extraction. Challenges included anti-scraping mechanisms like CAPTCHA, which were handled using tools like Octoparse. Web scraping enhances research by automating data collection for analysis, benefiting decision-making and large-scale studies,I also tried my level best to complete 4A but i couldn't make it will more on it in future\n","'''"],"metadata":{"id":"akAVJn9YBTQT","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1726434980045,"user_tz":300,"elapsed":164,"user":{"displayName":"VIJAY REDDY","userId":"13446931600515560470"}},"outputId":"46d07d0e-03dd-41cc-b0f0-516984b5b9d3"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n\\nWorking on web scraping tasks was a valuable experience, teaching key concepts like HTML structure, pagination, and dynamic content extraction. Challenges included anti-scraping mechanisms like CAPTCHA, which were handled using tools like Octoparse. Web scraping enhances research by automating data collection for analysis, benefiting decision-making and large-scale studies,I also tried my level best to complete 4A but i couldn't make it will more on it in future\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}